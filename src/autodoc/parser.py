import ast
import openai
import os
import re
from typing import List, Dict
from dotenv import load_dotenv

# Cargar variables de entorno desde .env (si existe)
load_dotenv()

class CodeParser:
    """
    Clase para analizar c√≥digo Python y extraer informaci√≥n detallada sobre docstrings.
    """

    def __init__(self, file_path: str):
        """
        Inicializa el analizador de c√≥digo.

        :param file_path: Ruta del archivo Python a analizar.
        """
        self.file_path = file_path
        self.tree = self._parse_file()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")

        if not self.openai_api_key:
            raise ValueError("‚ùå ERROR: La clave de API de OpenAI no est√° configurada.")

        openai.api_key = self.openai_api_key

    def _parse_file(self):
        """Lee y convierte el c√≥digo fuente en un √°rbol AST manteniendo el orden de los nodos."""
        with open(self.file_path, "r", encoding="utf-8") as file:
            return ast.parse(file.read())

    def extract_docstrings(self) -> List[Dict[str, str]]:
        """
        Extrae los docstrings y clasifica los elementos en m√≥dulos, clases y funciones,
        manteniendo el orden en que aparecen en el c√≥digo.

        :return: Lista de diccionarios con detalles de cada elemento analizado.
        """
        results = []

        for node in self.tree.body:  # Mantener el orden original
            if isinstance(node, (ast.Module, ast.ClassDef, ast.FunctionDef)):
                results.append(self._get_doc_info(node))

                if isinstance(node, ast.ClassDef):  # Si es clase, analizar m√©todos
                    for sub_node in node.body:
                        if isinstance(sub_node, ast.FunctionDef):
                            results.append(self._get_doc_info(sub_node, clase_padre=node.name))

        return results

    def _get_doc_info(self, node, clase_padre=None) -> Dict[str, str]:
        """Obtiene la informaci√≥n del docstring de un nodo (m√≥dulo, clase o funci√≥n)."""
        docstring = ast.get_docstring(node)
        tipo = "M√≥dulo" if isinstance(node, ast.Module) else "Clase" if isinstance(node, ast.ClassDef) else "M√©todo" if clase_padre else "Funci√≥n"

        return {
            "tipo": tipo,
            "nombre": f"{clase_padre}.{node.name}" if clase_padre else node.name,
            "docstring": docstring if docstring else "No documentado",
        }

    def evaluate_with_openai(self, elements: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        Eval√∫a la calidad de la documentaci√≥n con OpenAI.

        :param elements: Lista de elementos extra√≠dos del c√≥digo.
        :return: Lista con las evaluaciones agregadas.
        """
        prompt = (
            "Eval√∫a la calidad de la documentaci√≥n en el siguiente c√≥digo y califica cada elemento del 1 al 10.\n"
            "Clasificaci√≥n: 'Muy bien documentado', 'Documentaci√≥n aceptable', 'Falta documentaci√≥n', 'Mal documentado'.\n"
            "Si est√° mal documentado, sugiere mejoras.\n"
            "Devuelve la respuesta en este formato exacto:\n"
            "'Nombre: [nombre] | Puntuaci√≥n: [1-10] | Clasificaci√≥n: [texto]'.\n\n"
        )

        for elem in elements:
            prompt += f"- {elem['tipo']} `{elem['nombre']}`:\n  Docstring: {elem['docstring']}\n\n"

        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500
            )

            evaluation_text = response["choices"][0]["message"]["content"]

            # Extraer evaluaciones usando regex
            evaluations = {}
            pattern = r"Nombre: (.*?) \| Puntuaci√≥n: (\d+) \| Clasificaci√≥n: (.*?)$"
            matches = re.findall(pattern, evaluation_text, re.MULTILINE)

            for match in matches:
                nombre, puntuacion, clasificacion = match
                evaluations[nombre.strip()] = {
                    "puntuaci√≥n": puntuacion.strip(),
                    "clasificaci√≥n": clasificacion.strip()
                }

            # Agregar evaluaci√≥n a los elementos originales
            for elem in elements:
                nombre = elem["nombre"]
                if nombre in evaluations:
                    elem["puntuaci√≥n"] = evaluations[nombre]["puntuaci√≥n"]
                    elem["clasificaci√≥n"] = evaluations[nombre]["clasificaci√≥n"]
                else:
                    elem["puntuaci√≥n"] = "No evaluado"
                    elem["clasificaci√≥n"] = "No evaluado"

        except openai.error.OpenAIError as e:
            print(f"‚ùå ERROR de OpenAI: {str(e)}")
            for elem in elements:
                elem["puntuaci√≥n"] = "Error"
                elem["clasificaci√≥n"] = "No se pudo evaluar"

        return elements

    def generate_markdown_report(self, elements: List[Dict[str, str]], output_file="docs/evaluacion.md"):
        """
        Genera un reporte en formato Markdown con las evaluaciones.

        :param elements: Lista de elementos evaluados.
        :param output_file: Ruta del archivo Markdown de salida.
        """
        with open(output_file, "w", encoding="utf-8") as file:
            file.write("# üìÑ Reporte de Evaluaci√≥n de Documentaci√≥n\n\n")
            file.write("Este archivo contiene la evaluaci√≥n de la documentaci√≥n del c√≥digo analizado.\n\n")

            for resultado in elements:
                file.write(f"## üîπ {resultado['tipo']}: {resultado['nombre']}\n")
                file.write(f"**üìú Documentado:**\n```\n{resultado['docstring']}\n```\n")
                file.write(f"**üéØ Puntuaci√≥n:** {resultado.get('puntuaci√≥n', 'No evaluado')}\n\n")
                file.write(f"**üèÜ Clasificaci√≥n:** {resultado.get('clasificaci√≥n', 'No evaluado')}\n\n")
                file.write("---\n\n")

        print(f"‚úÖ Reporte generado: {output_file}")
